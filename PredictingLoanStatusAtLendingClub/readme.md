Lending Club is a lending company which provides personal and business loans. They release information such as income, employment, loan status,
etc. on loan applications. The goal of this project was to predict the probability of a personal loan in Lending Club to become charged off. This would help Lending Club have a better understanding of the risks of future applications. 

The dataset included 150 features and more than two million samples. The response variable was the loan status. Only samples whose loan status was charged-off or fully-paid were kept. Around 20 percent of these samples had a loan status of charged-off. In other words, it was an imbalanced dataset. Features which were not available at the time a loan application was submitted, features with unique value for each sample, and features with the same value across all samples were removed from the dataframe. 

Many features had more than 50 percent null values. Some of them were specific to the secondary applicants. These features were removed since less than 2 percent of the applications were joint and there was already a feature in the dataframe which indicated if an application was joint or individual. For the other features with more than 50 percent null values, the ratio of null values across different years was analyzed. It was concluded that some null values were representing missing values while the others were equivalent to zero. Features with more than 50 percent missing values were removed from the dataframe.

Some categorical features contained date or time; they were transformed to datetime format first, and then replaced with new categorical or numerical features based on the information extracted from them. For each categorical feature in the dataframe (except zip code and employment title), two plots were analyzed; a pie plot which showed the percentage of each level (unique value) of the feature, and a bar plot which showed the distribution of charged-off ratio across all levels of the feature. The two plots provided some insight about the feature. Also, if the ratio did not substantially change across different levels of a feature, it indicated the feature did not have a significant impact on the loan status and therefore, it was removed. 

Highly correlated numerical features were identified with the help of correlation heatmap. Only one feature from each group of highly correlated ones was kept and the rest were removed. Missing values of numerical features were filled with their median value. In some categorical features, more than 95% of samples had a zero value. These features were binarized, i.e. a new boolean feature corresponding to each of them was created. For each sample, the new feature was True if the original feature was zero, and False otherwise. Outliers of the numerical features were handled in two steps; first, they were capped and floored by applying conservative thresholds. Second, a boxcox or logarithmic transformation was applied on highly skewed features; the transformed version of these features was stored as new features. The original version of the binarized and transformed features were kept in the dataframe too.

Two categorical features, employment title and zip code, had a high cardinality problem, i.e. they had too many levels. With a 3-step cleaning process, the number of levels of the employment title was reduced by more than 53 percent. Then, the dataset was split into train and test sets. The split was stratified on the response variable since the dataset was imbalanced. In the train set, titles with frequency of lower than ten were replaced with ‘misc’. A new numerical feature was added to both train and test sets in the next step. In the train set, the value of the new feature corresponding to each level of the employment title was the charged-off ratio across all samples which shared that level. For each level in the test set, if the level existed in the train set, the numerical value corresponding to the level in the train set was assigned to the new feature in the test set, otherwise, the numerical value corresponding to ‘misc’ in the train set was assigned. A similar process was followed to create a new numerical feature in the train and test sets based on the zip code. At the end, the categorical format of both features were removed from the train and test sets.

The problem of imbalanced data was addressed by adjusting parameters of classifiers. Also, stratified folds were used in cross-validation processes. Two new train sets were created from the original train set; in the first one, the original version of the manipulated numerical features (those which were binarized or transformed) were excluded from the original train set. In the second train set, the binarized or transformed version of those features were excluded from the original train set.  Both train sets had 64 features. The categorical features were transformed to dummy variables and one dummy variable corresponding to each feature was removed. The first and second train sets were used in the logistic regression and XGBoost models, respectively, because some initial analysis indicated each model showed better results with the corresponding train set. 

The average 3-fold cross-validation accuracy score of the logistic regression model was 0.656. No improvement in the accuracy score was observed after parameter tuning and also adding interaction terms. Since the features were scaled as part of developing the logistic regression model, the absolute value of their coefficients represented their importance. Loan term, loan grade, loan amount, numeric employment title, and debt to income ratio were the five most important features to predict the probability of a loan to become charged-off according to the logistic regression model. The last three ones were numerical features; they were discretized into multiple bins and the charged-off ratio across the bins was analyzed. Five hyper parameters of the XGBoost model were tuned. The five most important features of the XGBoost model were interest rate, numeric employment title, loan amount, debt to income ratio, and annual income. The average 3-fold cross-validation accuracy score of the XGBoost model was only around 1.4% more than the score of the logistic regression model. The logistic regression model was more interpretable, and therefore, it was selected as the final model. At the end, the test score of the final model was computed; it was 0.655 which was only 0.2% less than the train score of the model.



Report: https://docs.google.com/document/d/1S99Rujjj_ekAYf4ji38Mi5q55JaPJedkUgKtO_ghLrU/edit?usp=sharing
Presentation: https://docs.google.com/presentation/d/1fE-CMOeFt8ID8lGjbXx7WgcoCMHSkhsF03v2rMzsqMI/edit?usp=sharing
